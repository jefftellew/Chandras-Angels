{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Campaign_Clicks_Pred_S.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.1"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yagnyaPatel/Chandras-Angels/blob/master/Campaign_Clicks_Pred_S.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z9xzjngkl3oK",
        "colab_type": "code",
        "outputId": "fe888876-5deb-420a-917a-cdadefbc6175",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import pylab as pl\n",
        "from pandas.plotting import scatter_matrix\n",
        "from matplotlib import cm\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import matplotlib.cm as cm\n",
        "from matplotlib.colors import ListedColormap, BoundaryNorm\n",
        "import matplotlib.patches as mpatches\n",
        "from datetime import datetime\n",
        "import pytz\n",
        "from dateutil import tz\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.externals import joblib\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.model_selection import RepeatedKFold\n",
        "from sklearn.svm import SVR\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import cross_val_score, cross_val_predict\n",
        "from sklearn.model_selection import cross_validate\n",
        "from sklearn import metrics\n",
        "from sklearn.model_selection import LeaveOneOut\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn import model_selection"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/externals/joblib/__init__.py:15: DeprecationWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n",
            "  warnings.warn(msg, category=DeprecationWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aeWpzG9_l3oP",
        "colab_type": "code",
        "outputId": "191a6c4d-7b61-4086-c4b8-1ef4fb5b566e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 442
        }
      },
      "source": [
        "#\n",
        "# sample_####_join.csv it's the data of the clicks and impressions of the campaign \n",
        "#\n",
        "# In this part merge function it's to join the impressions and clicks table\n",
        "#\n",
        "sample_clicks = pd.read_csv(\"ojpro_q4_fy18_clicks.csv\", low_memory = False);\n",
        "sample_impressions = pd.read_csv(\"ojpro_q4_fy18_impressions.csv\", low_memory = False);\n",
        "sample_clicks = sample_clicks.drop(['key','browser_id','region_id',\n",
        "                                                'placement', 'creative_type'], axis=1);\n",
        "sample = pd.merge(sample_impressions, sample_clicks, how='left').fillna(0);\n",
        "sample = sample.fillna(0);\n",
        "sample = sample[sample.impressions!= 1];\n",
        "sample['CTR'] = (sample['clicks']/sample['impressions'])*100;\n",
        "#sample.head()\n",
        "print(\"Clicks=\",sum(sample['clicks']))\n",
        "print()\n",
        "print(\"Impressions=\",sum(sample['impressions']))\n",
        "print()\n",
        "print(\"CTR=\",(sum(sample['clicks'])/sum(sample['impressions']))*100)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-66ab030e33e0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msample_clicks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"ojpro_q4_fy18_clicks.csv\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlow_memory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0msample_impressions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"ojpro_q4_fy18_impressions.csv\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlow_memory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m sample_clicks = sample_clicks.drop(['key','browser_id','region_id',\n\u001b[1;32m      4\u001b[0m                                                 'placement', 'creative_type'], axis=1);\n\u001b[1;32m      5\u001b[0m \u001b[0msample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmerge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample_impressions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_clicks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'left'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfillna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    700\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[1;32m    701\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 702\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    703\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    704\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    427\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    428\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 429\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    430\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    431\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    893\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 895\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    896\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1120\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'c'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1121\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'c'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1122\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1123\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1124\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'python'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1851\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'usecols'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1852\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1853\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1854\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1855\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] File b'ojpro_q4_fy18_clicks.csv' does not exist: b'ojpro_q4_fy18_clicks.csv'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SBY-7yEfl3oW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#\n",
        "# This function is to obtain the timezone of every state or region of US and CA\n",
        "#\n",
        "def f_timezone(row):\n",
        "    if row['state_region'] in ['AK']:\n",
        "        val = 'US/Alaska'\n",
        "    elif row['state_region'] in ['AL', 'AR', 'IA', 'IL', 'KS', 'LA', 'MN', 'MO', 'MS', 'ND', 'NE', 'OK','SD', 'TN','TX','WI']:\n",
        "        val = 'US/Central'\n",
        "    elif row['state_region'] in ['CT','DC','DE','FL','GA','IN','KY','MA','MD','ME','MI','NC',\n",
        "                                 'NH','NJ','NY','OH','ON','PA','QC','RI','SC','VA','VT','WV']:\n",
        "        val = 'US/Eastern'\n",
        "    elif row['state_region'] in ['AB','AZ','CO','ID','MT','NM','UT','WY']:\n",
        "        val = 'US/Mountain'\n",
        "    elif row['state_region'] in ['BC','CA','NV','OR','WA']:\n",
        "        val = 'US/Pacific'\n",
        "    elif row['state_region'] in ['HI']:\n",
        "        val = 'US/Hawaii'\n",
        "    else:\n",
        "        val = 'UTC'\n",
        "    return val\n",
        "#\n",
        "# This function is to obtain the real date and time of each time zone\n",
        "#\n",
        "def f_convert(row):\n",
        "    if row['Timezone'] in ['US/Alaska', 'US/Central', 'US/Eastern', 'US/Mountain','US/Pacific','US/Hawaii']:\n",
        "        val = row['date'].tz_localize('UTC').tz_convert(row['Timezone']).tz_localize(None)\n",
        "    else:\n",
        "        val = row['date'] \n",
        "    return val\n",
        "#\n",
        "# The next function creates a new class depending on the real time and the part of the day divided into 6 parts of 4 hrs\n",
        "#\n",
        "def f_day(row):\n",
        "    if row['hour'] in [23, 0, 1, 2] :\n",
        "        val = 'Middle_Night'\n",
        "    elif row['hour'] in [3, 4, 5, 6] :\n",
        "        val = 'Early_Morning'\n",
        "    elif row['hour'] in [7, 8, 9, 10] :\n",
        "        val = 'Morning'\n",
        "    elif row['hour'] in [11, 12, 13, 14]:\n",
        "        val = 'Midday'\n",
        "    elif row['hour'] in [15, 16, 17, 18] :\n",
        "        val = 'Evening'\n",
        "    elif row['hour'] in [19, 20, 21, 22] :\n",
        "        val = 'Night'\n",
        "    return val\n",
        "#\n",
        "# The next functions creates a new class depending on the CTR\n",
        "#\n",
        "##data = data.dropna(); \n",
        "#data = data.fillna('NAN');\n",
        "def f_CTR(row):\n",
        "    if row['CTR'] == 0:\n",
        "        val = 0\n",
        "    elif 0 < row['CTR'] <= 0.1:\n",
        "        val = 1\n",
        "    elif 0.1 < row['CTR'] <= 0.1:\n",
        "        val = 2\n",
        "    elif 0.1 < row['CTR'] <= 25:\n",
        "        val = 3\n",
        "    elif 25 < row['CTR'] <= 50:\n",
        "        val = 4\n",
        "    elif 50 < row['CTR'] <= 75:\n",
        "        val = 5\n",
        "    elif 75 < row['CTR'] <= 100:\n",
        "        val = 6\n",
        "    else:\n",
        "        val = 0\n",
        "    return val\n",
        "\n",
        "def f_CTR2(row):\n",
        "    if row['CTR'] == 0:\n",
        "        val = 0\n",
        "    elif 0 < row['CTR'] <= 0.1:\n",
        "        val = 1\n",
        "    elif 0.1 < row['CTR'] <= 1:\n",
        "        val = 2\n",
        "    elif 1 < row['CTR'] <= 100:\n",
        "        val = 3\n",
        "    else:\n",
        "        val = 0\n",
        "    return val\n",
        "\n",
        "def f_CTR3(row):\n",
        "    if row['CTR'] == 0:\n",
        "        val = 0\n",
        "    else:\n",
        "        val = 1\n",
        "    return val\n",
        "\n",
        "\n",
        "#\n",
        "# The next functions creates a new class depending on the operating_system to get the device info\n",
        "#\n",
        "def device(row):\n",
        "    if any(word in row['operating_system'] for word in ['Microsoft', 'Unix', 'Linux', 'Macintosh']):\n",
        "        val = 'PC/Mac'\n",
        "    elif any(word in row['operating_system'] for word in ['Android', 'Apple iOS', 'Windows Phone',\n",
        "                                                          'Nokia','BlackBerry', 'Palm', 'DoCoMo', 'Samsung']):\n",
        "        val = 'Mobile'\n",
        "    else:\n",
        "        val = 'Others'\n",
        "    return val\n",
        "\n",
        "#\n",
        "# Function to separe the placement string\n",
        "#\n",
        "def f_audience(row):\n",
        "    if len(row['placement'].split('_')) == 7:\n",
        "        val = row.str.split('_').str[2]\n",
        "    elif len(row['placement'].split('_')) == 8:\n",
        "        val = row.str.split('_').str[2]\n",
        "    else:\n",
        "        val = 0\n",
        "    return val\n",
        "\n",
        "def f_dates(row):\n",
        "    if len(row['placement'].split('_')) == 7:\n",
        "        val = row.str.split('_').str[3]\n",
        "    elif len(row['placement'].split('_')) == 8:\n",
        "        val = row.str.split('_').str[4]\n",
        "    else:\n",
        "        val = 0\n",
        "    return val\n",
        "\n",
        "def f_ad_size(row):\n",
        "    if len(row['placement'].split('_')) == 7:\n",
        "        val = row.str.split('_').str[4]\n",
        "    else:\n",
        "        val = row.str.split('_').str[5]\n",
        "    return val"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_-BEH0Rzl3ob",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sample['Device'] = sample.apply(device, axis=1);\n",
        "sample['CTR_Class'] = sample.apply(f_CTR, axis=1);\n",
        "sample['CTR_Class2'] = sample.apply(f_CTR2, axis=1);\n",
        "sample['Timezone'] = sample.apply(f_timezone, axis=1);\n",
        "sample['date'] =  pd.to_datetime(sample['date'], format=\"%Y/%m/%d-%H\")\n",
        "sample['local_date'] = sample.apply(f_convert, axis=1)\n",
        "sample['Day_id'] = pd.to_datetime(sample['local_date'], format='%Y-%m-%dT%H:%M:%S').dt.strftime('%w');\n",
        "sample['Day'] = pd.to_datetime(sample['local_date'], format='%Y-%m-%dT%H:%M:%S').dt.strftime('%A');\n",
        "sample['hour'] = pd.to_datetime(sample['local_date'], format='%Y-%m-%dT%H:%M:%S').dt.hour;\n",
        "sample['Day_Part'] = sample.apply(f_day, axis=1);\n",
        "\n",
        "if sample['placement'].astype(str).str.split('_').map(len) == 8:\n",
        "        sample['placement_ad_size'] = sample['placement'].str.split('_').str[5]\n",
        "        sample['placement_audience'] = sample['placement'].str.split('_').str[2]\n",
        "        sample['placement_date'] = sample['placement'].str.split('_').str[4]    \n",
        "else:\n",
        "        sample['placement_ad_size'] = sample['placement'].str.split('_').str[4]\n",
        "        sample['placement_audience'] = sample['placement'].str.split('_').str[2]\n",
        "        sample['placement_date'] = sample['placement'].str.split('_').str[3]\n",
        "        \n",
        "#sample['placement_ad_size'].replace('080118-091518', '1x1', inplace=True);    \n",
        "sample.head() "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R9Ucobgzl3of",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sample.groupby('placement_ad_size').placement_ad_size.count()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A7gDRMjDl3oj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "len(sample['placement'].iloc[10].split('_')) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m2cyzgFHl3oq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sample['adsize'] = sample.apply(f_ad_size, axis=1);"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OygS96qxl3ov",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dMsO8R-Vl3oz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QQTzhpv4l3o3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sample.to_csv('ojpro_full_sample_q4_fy18.csv');"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S-HQRDf9l3o7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(\"Clicks=\",sum(sample['clicks']))\n",
        "print()\n",
        "print(\"Impressions=\",sum(sample['impressions']))\n",
        "print()\n",
        "print(\"CTR=\",(sum(sample['clicks'])/sum(sample['impressions']))*100)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T6i6O2x_l3pB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "##########################################################################################################################   \n",
        "##########################################################################################################################\n",
        "## If the full sample is already in the folder, Start here ##\n",
        "##########################################################################################################################    \n",
        "##########################################################################################################################    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "npWs1lDol3pE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sample = pd.read_csv(\"ojpro_full_sample_q4_fy18.csv\", low_memory = False);"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RKTisHg6l3pI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(\"Clicks=\",sum(sample['clicks']))\n",
        "print()\n",
        "print(\"Impressions=\",sum(sample['impressions']))\n",
        "print()\n",
        "print(\"CTR=\",(sum(sample['clicks'])/sum(sample['impressions']))*100)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gWy7C00Wl3pO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def f_CR(row):\n",
        "    if row['CTR'] == 0  :\n",
        "        val = 0\n",
        "    else:\n",
        "        val = 1\n",
        "    return val\n",
        "sample['CR'] = sample.apply(f_CR, axis=1);"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mj2UzyIcl3pR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sample3 = sample.drop(sample[(sample['clicks'] == 0) & (sample['impressions'] <= 30)].index)\n",
        "sample3 = sample3.drop(sample3[(sample3['CTR_Class2'] == 1)].index)\n",
        "#sample3 = sample;\n",
        "sample3[['ad_size_id']] = sample3[['placement_ad_size']].apply(lambda x: pd.factorize(x)[0] + 1)\n",
        "sample3[['Timezone_id']] = sample3[['Timezone']].apply(lambda x: pd.factorize(x)[0]+ 1 )\n",
        "sample3[['day_part_id']] = sample3[['Day_Part']].apply(lambda x: pd.factorize(x)[0] + 1)\n",
        "sample3[['Device_id']] = sample3[['Device']].apply(lambda x: pd.factorize(x)[0] + 1)\n",
        "features = ['ad_size_id','Timezone_id','day_part_id', 'region_id', 'hour','Day_id', 'browser_id', 'Device_id']\n",
        "target = 'CR';"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wcjqg8VRl3pV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(\"Percentage of CTR Class in full sample:\")\n",
        "print()\n",
        "print(sample['CR'].value_counts(normalize=True) * 100)\n",
        "print()\n",
        "print(\"Clicks=\",sum(sample['clicks']))\n",
        "print()\n",
        "print(\"Impressions=\",sum(sample['impressions']))\n",
        "print()\n",
        "print(\"CTR=\",(sum(sample['clicks'])/sum(sample['impressions']))*100)\n",
        "print()\n",
        "print(\"Percentage of CTR Class better distributed:\")\n",
        "print()\n",
        "print(sample3['CR'].value_counts(normalize=True) * 100)\n",
        "print()\n",
        "print(\"Clicks=\",sum(sample3['clicks']))\n",
        "print()\n",
        "print(\"Impressions=\",sum(sample3['impressions']))\n",
        "print()\n",
        "print(\"CTR=\",(sum(sample3['clicks'])/sum(sample3['impressions']))*100)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eLTissXhl3pg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X = sample3[features]\n",
        "y = sample3['CTR_Class2']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y,  test_size=0.25, random_state = 10)\n",
        "scaler = MinMaxScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test) \n",
        "\n",
        "print (X_train.shape, y_train.shape)\n",
        "print (X_test.shape, y_test.shape)\n",
        "\n",
        "rfs= RandomForestClassifier(n_estimators = 100, max_depth = 20, random_state=42);\n",
        "rfs.fit(X_train, y_train);"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yOmG_1i3l3pu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "predictions = rfs.predict(X_test)\n",
        "#print(\"Score:\", rfs.score(y_test, predictions))\n",
        "metrics.accuracy_score(y_test, predictions)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zh8w00Ckl3p2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Precision in the training sample\n",
        "print(\"Training Precision: {0: .4f}\".format(\n",
        "        rfs.score(X_train, y_train)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F_Yu4amrl3qE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Precision in the evaluation sample \n",
        "print(\"Evaluation precision: {0: .4f}\".format(\n",
        "        rfs.score(X_test, y_test)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1WK2Jtx-l3qU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sample3.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_zG1XhiFl3qa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sample3.groupby('Device').Device.count()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wxg7IPzrl3qh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def one_hot_obj_features(df, features):\n",
        "    new_df = pd.get_dummies(df, columns=features, sparse=True)\n",
        "    return new_df"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9aTk2K_Wl3ql",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "features = ['placement_ad_size','Timezone','Day_Part', 'state_region', 'hour','Day', 'browser_platform', 'Device']\n",
        "target = 'CR';\n",
        "train_sample = sample3[features + [target]].sample(frac=0.25, random_state=21)\n",
        "train_sample = one_hot_obj_features(train_sample, ['placement_ad_size','Timezone','Day_Part', \n",
        "                                                   'state_region', 'hour','Day', 'browser_platform', 'Device'])\n",
        "\n",
        "model_features = np.array(train_sample.columns[train_sample.columns != target].tolist())\n",
        "X = train_sample[model_features].values;\n",
        "y = train_sample[target].values;\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    train_sample[model_features].values, \n",
        "    train_sample[target].values,\n",
        "    test_size=0.25,\n",
        "    random_state=21\n",
        ")\n",
        "\n",
        "rfs= RandomForestClassifier(n_estimators = 100, max_depth = 50, random_state=42);\n",
        "rfs.fit(X_train, y_train);"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vZsSJ77Ol3qp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "predictions = rfs.predict(X_test)\n",
        "#print(\"Score:\", rfs.score(y_test, predictions))\n",
        "metrics.accuracy_score(y_test, predictions)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "8wvCre-Tl3qv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "rfs.fit(X_train, y_train);\n",
        "rfs_cv_score = cross_val_score(rfs, X, y, cv=5, scoring='accuracy')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YzwVGeuil3qz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print('Accuracy of Random Forest classifier on training set: {:.2f}'\n",
        "     .format(rfs.score(X_train, y_train)))\n",
        "print('Accuracy of Random Forest classifier on test set: {:.2f}'\n",
        "     .format(rfs.score(X_test, y_test)))\n",
        "print()\n",
        "print()\n",
        "print(\"=== Confusion Matrix ===\")\n",
        "print(confusion_matrix(y_test, predictions))\n",
        "print('\\n')\n",
        "print(\"=== Classification Report ===\")\n",
        "print(classification_report(y_test, predictions))\n",
        "print('\\n')\n",
        "print(\"=== All Accuracy Scores ===\")\n",
        "print(rfs_cv_score)\n",
        "print('\\n')\n",
        "print(\"=== Mean }Accuracy Score ===\")\n",
        "print(\"Mean Accuracy Score - Random Forest: \", rfs_cv_score.mean())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ABVFY-c0l3q4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cross_val_score(rfs, X, y, cv=4).mean()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "aLvCd1Agl3q7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "scores = cross_val_score(rfs, X, y, cv=6)\n",
        "scores"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "aXG6NdCTl3rB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.externals import joblib\n",
        "\n",
        "#feature_names = ['ad_size_id','Timezone_id','day_part_id', 'region_id', 'hour','Day_id', 'browser_id', 'Device_id']\n",
        "#X = sample3[feature_names]\n",
        "#y = sample3['CTR_Class2']\n",
        "\n",
        "kfold = model_selection.KFold(n_splits=10, random_state=21)\n",
        "scoring = 'accuracy'\n",
        "####################################################################\n",
        "#######  Create Training and Test Sets and Apply Scaling ###########\n",
        "####################################################################\n",
        "#X_train, X_test, y_train, y_test = train_test_split(X, y,  test_size=0.25, random_state = 10)\n",
        "#scaler = MinMaxScaler()\n",
        "#X_train = scaler.fit_transform(X_train)\n",
        "#X_test = scaler.transform(X_test) \n",
        "####################################################################\n",
        "#######################  Logistic Regression #######################\n",
        "####################################################################\n",
        "logreg = LogisticRegression(solver='lbfgs',multi_class='auto')\n",
        "logreg.fit(X_train, y_train)\n",
        "print()\n",
        "print('Accuracy of Logistic regression classifier on training set: {:.2f}'\n",
        "      .format(logreg.score(X_train, y_train)))\n",
        "print('Accuracy of Logistic regression classifier on test set: {:.2f}'\n",
        "      .format(logreg.score(X_test, y_test)))\n",
        "results = model_selection.cross_val_score(logreg, X, y, cv=kfold, scoring=scoring)\n",
        "print(\"Accuracy (Cross Validation Classification Accuracy):\", results.mean())\n",
        "print()\n",
        "print()\n",
        "print(\"Logistic Regression\")\n",
        "pred = logreg.predict(X_test)\n",
        "print()\n",
        "print(confusion_matrix(y_test, pred))\n",
        "print()\n",
        "print(classification_report(y_test, pred))\n",
        "####################################################################\n",
        "#######################    Decision Tree     #######################\n",
        "####################################################################\n",
        "dtc = DecisionTreeClassifier().fit(X_train, y_train)\n",
        "print()\n",
        "print('Accuracy of Decision Tree classifier on training set: {:.2f}'\n",
        "     .format(dtc.score(X_train, y_train)))\n",
        "print('Accuracy of Decision Tree classifier on test set: {:.2f}'\n",
        "     .format(dtc.score(X_test, y_test)))\n",
        "results = model_selection.cross_val_score(dtc, X, y, cv=kfold, scoring=scoring)\n",
        "print(\"Accuracy (Cross Validation Classification Accuracy):\", results.mean())\n",
        "print()\n",
        "####################################################################\n",
        "######################  K-Nearest Neighbors  #######################\n",
        "####################################################################\n",
        "knn = KNeighborsClassifier()\n",
        "knn.fit(X_train, y_train)\n",
        "print()\n",
        "print('Accuracy of K-Nearest Neighbors classifier on training set: {:.2f}'\n",
        "     .format(knn.score(X_train, y_train)))\n",
        "print('Accuracy of K-Nearest Neighbors classifier on test set: {:.2f}'\n",
        "     .format(knn.score(X_test, y_test)))\n",
        "results = model_selection.cross_val_score(knn, X, y, cv=kfold, scoring=scoring)\n",
        "print(\"Accuracy (Cross Validation Classification Accuracy):\", results.mean())\n",
        "print()\n",
        "print()\n",
        "print(\"K-Nearest Neighbors\")\n",
        "pred = knn.predict(X_test)\n",
        "print()\n",
        "print(confusion_matrix(y_test, pred))\n",
        "print()\n",
        "print(classification_report(y_test, pred))\n",
        "####################################################################\n",
        "#############  Linear Discriminant Analysis  #######################\n",
        "####################################################################\n",
        "lda = LinearDiscriminantAnalysis()\n",
        "lda.fit(X_train, y_train)\n",
        "print()\n",
        "print('Accuracy of Linear Discriminant Analysis classifier on training set: {:.2f}'\n",
        "     .format(lda.score(X_train, y_train)))\n",
        "print('Accuracy of Linear Discriminant Analysis classifier on test set: {:.2f}'\n",
        "     .format(lda.score(X_test, y_test)))\n",
        "results = model_selection.cross_val_score(lda, X, y, cv=kfold, scoring=scoring)\n",
        "print(\"Accuracy (Cross Validation Classification Accuracy):\", results.mean())\n",
        "print()\n",
        "####################################################################\n",
        "#####################  Gaussian Naive Bayes  #######################\n",
        "####################################################################\n",
        "gnb = GaussianNB()\n",
        "gnb.fit(X_train, y_train)\n",
        "print()\n",
        "print('Accuracy of Gaussian NB classifier on training set: {:.2f}'\n",
        "     .format(gnb.score(X_train, y_train)))\n",
        "print('Accuracy of Gaussian NB classifier on test set: {:.2f}'\n",
        "     .format(gnb.score(X_test, y_test)))\n",
        "results = model_selection.cross_val_score(gnb, X, y, cv=kfold, scoring=scoring)\n",
        "print(\"Accuracy (Cross Validation Classification Accuracy):\", results.mean())\n",
        "print()\n",
        "####################################################################\n",
        "###################  Support Vector Machine  #######################\n",
        "####################################################################\n",
        "svm = SVC(gamma='auto')\n",
        "svm.fit(X_train, y_train)\n",
        "print()\n",
        "print('Accuracy of Support Vector Machine classifier on training set: {:.2f}'\n",
        "     .format(svm.score(X_train, y_train)))\n",
        "print('Accuracy of Support Vector Machine classifier on test set: {:.2f}'\n",
        "     .format(svm.score(X_test, y_test)))\n",
        "results = model_selection.cross_val_score(svm, X, y, cv=kfold, scoring=scoring)\n",
        "print(\"Accuracy (Cross Validation Classification Accuracy):\", results.mean())\n",
        "print()\n",
        "print()\n",
        "print(\"Support Vector Machine\")\n",
        "pred = svm.predict(X_test)\n",
        "print()\n",
        "print(confusion_matrix(y_test, pred))\n",
        "print()\n",
        "print(classification_report(y_test, pred))\n",
        "####################################################################\n",
        "######################     Random Forest    #######################\n",
        "####################################################################\n",
        "rf = RandomForestClassifier(n_estimators = 500)\n",
        "rf.fit(X_train, y_train)\n",
        "print()\n",
        "print('Accuracy of Random Forest classifier on training set: {:.2f}'\n",
        "     .format(rf.score(X_train, y_train)))\n",
        "print('Accuracy of Random Forest classifier on test set: {:.2f}'\n",
        "     .format(rf.score(X_test, y_test)))\n",
        "results = model_selection.cross_val_score(rf, X, y, cv=kfold, scoring=scoring)\n",
        "print(\"Accuracy (Cross Validation Classification Accuracy):\", results.mean())\n",
        "print()\n",
        "####################################################################\n",
        "######################                       #######################\n",
        "####################################################################\n",
        "print()\n",
        "print(\"Decision Tree\")\n",
        "pred = dtc.predict(X_test)\n",
        "print()\n",
        "print(confusion_matrix(y_test, pred))\n",
        "print()\n",
        "print(classification_report(y_test, pred))\n",
        "print()\n",
        "print()\n",
        "print(\"Random Forest\")\n",
        "pred2 = rf.predict(X_test)\n",
        "print()\n",
        "print(confusion_matrix(y_test, pred2))\n",
        "print()\n",
        "print(classification_report(y_test, pred2))\n",
        "print()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xZDlpCL1l3rM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pd.crosstab(y_test,pd.Series(pred2),rownames=['ACTUAL'],colnames=['PRED'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MFZXhA1Vl3rR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}